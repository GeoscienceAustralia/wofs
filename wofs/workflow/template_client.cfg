[wofs]
# A unique identifier is assigned to each WOfS run. From user input or auto-gen
run_id = ${run_id}
# BaseDir is where the accumulative extents, sia, shadows, etc are kept to save re-computing.
# Operators do not change.
base_dir = ${base_dir}

# All WOfS programs use the working_dirctory as the "present working directory"
# All logging and temporary files go to this directory as do the key WOfS output product
# The policy is to use /g/data/u46/wofs as the base for WOfS working directory
# The run_id is incorporated into the working directory name to allow different runs to be
# clearly deliniated.
working_dir = %(base_dir)s/wofs_%(run_id)s

# scratch_dir refers to the directory where WOfS writes all intermediate result files
#
# WOfS generates large numbers of scratch files and deletes them when they are no
# longer required by the workflow. Placing the scratch directory in the working_dir
# ensures that WOfS runs are fully re-runnable (WOfS will reuse exsiting intermediate
# files in the scratch area to resume processing when a Luigi job is resubmitted.
#
# setting scratch_dir to the empty string will result in the scratch directory being created
# on PBS_JOBFS or /tmp file system. Whilst this may prove to be more efficient for some
# processing (short, incremental WoFS updates) it is not recommended for full
# continental runs involving the whole continent. Handle this parameter with care!
 
# scratch_dir = 
scratch_dir = %(working_dir)s/scratch

# All logging is controlled by the ``logging.cfg`` file which is copied to the working 
# directory from source for each run. The ``logging.cfg`` file may be amended before each
# run or step within a run. Log files are copied to the following directory by PBS scripts

logs_dir = %(working_dir)s/logs

# A directory containing water extents organised into 
# "cell subdirectories". e.g. ./extents/150_-034 contains WOfS water extent geotiffs
# for cell 150_-034
#
# Incremental WOfS runs are implemented by re-using an extents directory shared by 
# each new run of WOfS as follows - thus only new AGDC NBAR tiles will be processed
# to produce new water extents...

extents_dir = %(base_dir)s/extents

# ... or, you can re-process ALL NBAR tiles by creating a new extents directory
# exclusively for this run

## extents_dir = %(working_dir)s/extents

# A shadow mask is created for each NBAR tile being processed by WOfS. Each shadow mask
# contains two bands, 1. The solar incident angle to terrain and 2. The cast shadow state
# for the pixel (in shade, true/false). The creation of a shadow mask is very expensive 
# so WOfS caches each mask to a directory reuse in later WOfS runs. The path below points
# to that directory containing shadow masks organised into 
# "cell subdirectories". e.g. ./shadows/150_-034 contains shadow mask geotiffs
# for cell 150_-034 -- one shadow mask per NBAR scene being processed

shadow = %(base_dir)s/shadows

# To create a shadow mask for each NBAR tile, WOfS requires a DSM tils with a 250 pixel
# border. The border prevents edge effects during ray tracing computation. Assembling
# a bordered DSM tile is computationally expensive so, once created, these tiles are 
# stored permanenty (for later reuse) in the directory below.
# To ensure reuse, this directory should be in the base_dir

bordered_elev_tile_path = %(base_dir)s/bordered_elevation

# path to directory containing Digital Surface Model (DSM) tiles. File in this 
# directory have the format DSM_<long>_<lat>.tif

dsm_path = /g/data/rq6/DSM/EPSG4326_1deg_0.00025pixel/dsm1sv1_0_Clean.img

# A Terrain shadow Mask File is created for each (tsm)

# A terrain shadow mask (tsm) is created for each NBAR tile being processed by WOfS. 
# Each shadow mask contains two bands the cast shadow state
# for each  pixel (in shade, true/false). The creation of a TSM is very expensive 
# so WOfS caches each mask to a directory for reuse in later WOfS runs. The path below points
# to that directory containing TSMs organised into 
# "cell subdirectories". e.g. ./shadows/150_-034 contains shadow mask geotiffs
# for cell 150_-034 -- one shadow mask per NBAR scene being processed

tsm_dir=%(base_dir)s/shadows

# Directory where Solar Incident Angle (SIA) tiles are stored
# Like the TSMs a SIA tile is created for each NBAR tile being processed by WOfS
# A pixel value in a single SIA tile represents the solar incident angle to the terrain
# in degrees above the tangent to the terrain slope. SIA tiles are organised in 
# "cell subdirectories in a manner similar to TSM tiles (see above) 

sia_dir=%(base_dir)s/sia

# During the wofs_discovery step, the AGDC API is queried to obtain details of all
# NBAR and PQ tiles for all cells in the current coverage. CVS files containing
# details of these files are written to the following directory and used as 
# input for subsequent WOfS processing steps

input_dir=%(working_dir)s/inputs

# Water summary files (one per AGDC cell) are written to the following directory
# during the 'wofs_summary' stage of processing

summaries_dir = %(working_dir)s/summaries

# The Image Pyramids which form one of the may outputs of WOfS are written to the
# following directory during the 'wofs_pyramids' stage of processing

pyramids_dir = %(working_dir)s/pyramids

# output from a WOfS audit process is placed here 

audit_dir = %(working_dir)s/audit

# Pixels which have a solar incident to terrain angle less that than the 
# specified value are masked out. The value is in degrees to the terrain tangent plane

low_solar_incident_threshold=30

# Pixels where the DSM indicates a high slope are masked out. The limit value is in degrees
# to horizontal

slope_limit_degrees=12.0

# fuzzy_secs allows for some variation in the timestamp associated with Datacube tiles
# Timestamps within the 'fuzzy_sec' time interval are deemed to be identical
# time window for water extents (in seconds)

extent_tile_fuzzy_secs = 10

# time window for shadow and solar incident tiles (in decimal years)
# 30 minutes = .5 / 24 / 365.24 = 5.704011974e-5

shadow_tile_fuzzy_delta = 5.704011974e-5


# confidence data
phat_pmin_dir = %(working_dir)s/confidence/pmin
factor_dir = %(base_dir)s/confidence
training_cells_dir=%(base_dir)s/confidence/Training
mrvbf_dir = %(base_dir)s/confidence/MrVBF
geoFabric_dir = %(base_dir)s/confidence/geoFabric
urbanAreas_dir = %(base_dir)s/confidence/urbanAreas
modis_dir = %(base_dir)s/confidence/modis
confidence_factors = mrvbf,modis,slope,phat,geofabric_canal,geofabric_foreshore,geofabric_pondage,geofabric_reservoir,geofabric_flat,geofabric_lake,geofabric_rapid,geofabric_swamp,geofabric_watercourse,urbanareas
GEOFABRIC = unclassified,canal,flat,foreshore,pondage,rapid,watercourse,lake,reservoir,swamp

geofabric_tile = %(geoFabric_dir)s/tiles/GEOFABRIC_%%s.tif
urbanArea_tile = %(urbanAreas_dir)s/tiles/'ABSDATA_%%s.tif
mrvbf_tile = 


# confidence processing

phat_confidence=90.0
training_C = 1.0
training_penalty = l2
confidence_threshold = 1.0

# confidence outputs

confidence_base_dir=%(working_dir)s/confidence
trained_model_path=%(confidence_base_dir)s/model/confidence_model.pkl
confidence_output_dir=%(confidence_base_dir)s/tiles

# The following specifies the temporal and spatial coverage for this WOfS run together with which 
# satellites are to be processed, [minv, maxv)

#All Aust [min, max)
#lat_min_deg = -45
#lat_max_deg = -4
#lon_min_deg = 111
#lon_max_deg = 154

[coverage]
lat_min_deg = ${lat_min_deg}    #-36
lat_max_deg = ${lat_max_deg}    #-35
lon_min_deg = ${lon_min_deg}    #149
lon_max_deg = ${lon_max_deg}    #155

start_datetime = ${start_datetime}
end_datetime = ${end_datetime}

satellites = ${satellites}          # LS5,LS7,LS8

# list of cells to exclude from processing
# exclude_cells=[[150,-33],[150,-34]]

# list of cells to include. If this list is empty or the parameter absent, ALL datacube cells within 
# the bounds of the coverage are included.
# The following are WOfS test cells

# include_cells=[[115,-32],[119,-25],[122,-33],[124,-28],[132,-13],[132,-23],[137,-28],[139,-25],[139,-31],[142,-16],[142,-32],[143,-36],[144,-38],[145,-17],[146,-43],[147,-37],[149,-35],[149,-36],[150,-27],[150,-34],[139,-36],[139,-37],[139,-38],[140,-36],[140,-37],[140,-38],[140,-39],[130,-13],[144,-39],[145,-39],[153,-28],[123,-17],[123,-18],[146,-39],[149,-38],[121,-29],[142,-22],[118,-23],[146,-34],[135,-18]]

[logs]
# a sub directory of the working directory. Futher sub-directories are maintained for
# each major processing step
path = ./logs
level = INFO

[core]
logging_conf_file = %{working_dir}s/logging.cfg


[inputs]
# a sub directory of the working directory containing:
#   - tiles.csv               -- contains all tiles selected from the datacube
#   - cell_tiles_150_-034.csv -- contains tiles for one cell 
path = ./inputs

[shadows]
# A shadow mask is created for each NBAR tile being processed by WOfS. Each shadow mask
# contains two bands, 1. The solar incident angle to terrain and 2. The cast shadow state
# for the pixel (in shade, true/false). The creation of a shadow mask is very expensive 
# so WOfS caches each mask to a directory reuse in later WOfS runs. The path below points
# to that directory containing shadow masks organised into 
# "cell subdirectories". e.g. ./shadows/150_-034 contains shadow mask geotiffs
# for cell 150_-034 -- one shadow mask per NBAR scene being processed
path = /g/data/u46/wofs/shadows
# To create a shadow mask for each NBAR tile, WOfS requires a DSM tils with a 250 pixel
# border. The border prevents edge effects during ray tracing computation. Assembling
# a bordered DSM tile is computationally expensive so, once created, these tiles are 
# stored permanenty (for later reuse) in the directory below.
bordered_dsm_tile_path = /g/data/u46/wofs/bordered_dsm
# path to directory containing DSM tiles. File this directory have the format
# DSM_<long>_<lat>.tif
dsm_path = /g/data/rq6/DSM/EPSG4326_1deg_0.00025pixel/dsm1sv1_0_Clean.img

# PBS defaults to be used for 'submit' jobs

[pbs]
module_use = /projects/u46/opt/modules/modulefiles
modules = wofs
project = u46
queue = normal
email = fei.zhang@ga.gov.au

# PBS override parameters for wofs_summary job

[wofs_summary_pbs]
queue = express
#FZ walltime = 5:00:00
walltime = 00:50:00
nnodes = 2

# PBS override parameters for confidence training job

[train_confidence_pbs]
walltime = 2:00:00
# mem is in GBs -- note, large memory requirement
mem = 61
ncpus = 2
queue = normal

# PBS override parameters for pyramid generation job

[wofs_pyramids_pbs]
#walltime = 4:00:00
walltime = 1:00:00
mem = 60
queue = express
#queue = normal
